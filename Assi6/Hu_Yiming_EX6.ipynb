{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "from NEMtropy import UndirectedGraph, DirectedGraph\n",
    "from NEMtropy.network_functions import build_adjacency_from_edgelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A06.1 - Exponential Random Graph Models\n",
    "\n",
    "Task: For the World Trade Web dataset, fit different ERGM-based Configuration Models and compare basic network metrics with null models\n",
    "\n",
    "For each of the WTW networks provided:\n",
    "\n",
    "+ measure the average clustering and reciprocity coefficients\n",
    "\n",
    "+ fit the Undirected Binary CM and Directed Binary CM\n",
    "\n",
    "+ sample 30 networks from the obtained distributions and measure clustering and reciprocity. Calculate average and standard error on each measure\n",
    "\n",
    "+ plot clustering and reciprocity as functions of time, comparing the real value with the average and error bars from samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 datasets have been loaded\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "year_load = 1992\n",
    "graphs = []\n",
    "\n",
    "while year_load < 2003:\n",
    "    file_name = \"data/World_Trade_Web/WDN_\"+str(year_load)+\".txt.graphml\"\n",
    "    graph = nx.read_graphml(file_name)\n",
    "    graphs.append(graph)\n",
    "    year_load = year_load + 1\n",
    "\n",
    "print(str(len(graphs)) + \" datasets have been loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Year of 1992-------------\n",
      "Average clustering: 0.8021364732946835\n",
      "Reciprocity coefficients: 0.367340010185028\n",
      "-------------Year of 1993-------------\n",
      "Average clustering: 0.7826552252417198\n",
      "Reciprocity coefficients: 0.430931744312026\n",
      "-------------Year of 1994-------------\n",
      "Average clustering: 0.778118724128831\n",
      "Reciprocity coefficients: 0.541138903672166\n",
      "-------------Year of 1995-------------\n",
      "Average clustering: 0.769316598518603\n",
      "Reciprocity coefficients: 0.6043664931031333\n",
      "-------------Year of 1996-------------\n",
      "Average clustering: 0.779859983253989\n",
      "Reciprocity coefficients: 0.6482433229421182\n",
      "-------------Year of 1997-------------\n",
      "Average clustering: 0.7844618494148852\n",
      "Reciprocity coefficients: 0.6822429906542056\n",
      "-------------Year of 1998-------------\n",
      "Average clustering: 0.7913458153848136\n",
      "Reciprocity coefficients: 0.7015887290167866\n",
      "-------------Year of 1999-------------\n",
      "Average clustering: 0.7946922756897296\n",
      "Reciprocity coefficients: 0.716582186821144\n",
      "-------------Year of 2000-------------\n",
      "Average clustering: 0.7928732278480053\n",
      "Reciprocity coefficients: 0.7232351897836112\n",
      "-------------Year of 2001-------------\n",
      "Average clustering: 0.8020845961993215\n",
      "Reciprocity coefficients: 0.7375525101577026\n",
      "-------------Year of 2002-------------\n",
      "Average clustering: 0.7955013137787762\n",
      "Reciprocity coefficients: 0.7041909280425562\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Average clustering and reciprocity\n",
    "year_load = 1992\n",
    "ave_clust = []\n",
    "reci_coe = []\n",
    "\n",
    "for graph in graphs:\n",
    "    print(\"-------------Year of \" + str(year_load) + \"-------------\")\n",
    "    ave_clust.append(nx.average_clustering(graph))\n",
    "    print(\"Average clustering: \" + str(nx.average_clustering(graph)))\n",
    "    reci_coe.append(nx.reciprocity(graph))\n",
    "    print(\"Reciprocity coefficients: \" + str(nx.reciprocity(graph)))\n",
    "    year_load = year_load + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Year of 1992-------------\n",
      "\n",
      "solution error = 7.642569244126207e-09\n",
      "\n",
      "solution error = 3.302488948975224e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/numba/core/utils.py:612: NumbaExperimentalFeatureWarning: First-class function type feature is experimental\n",
      "  warnings.warn(\"First-class function type feature is experimental\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Year of 1993-------------\n",
      "\n",
      "solution error = 5.087997578812065e-09\n",
      "\n",
      "solution error = 2.7070257146988297e-09\n",
      "-------------Year of 1994-------------\n",
      "\n",
      "solution error = 2.507334784240811e-09\n",
      "\n",
      "solution error = 2.99346325505212e-09\n",
      "-------------Year of 1995-------------\n",
      "\n",
      "solution error = 2.1745449885202106e-09\n",
      "\n",
      "solution error = 2.9240538879093947e-09\n",
      "-------------Year of 1996-------------\n",
      "\n",
      "solution error = 2.9924365207989467e-09\n",
      "\n",
      "solution error = 2.0478942985846516e-09\n",
      "-------------Year of 1997-------------\n",
      "\n",
      "solution error = 2.010949629038805e-09\n",
      "\n",
      "solution error = 1.7757031400833512e-09\n",
      "-------------Year of 1998-------------\n",
      "\n",
      "solution error = 2.9665159217984183e-09\n",
      "\n",
      "solution error = 2.540105015214067e-09\n",
      "-------------Year of 1999-------------\n",
      "\n",
      "solution error = 1.137834715336794e-09\n",
      "\n",
      "solution error = 3.322952579765115e-09\n",
      "-------------Year of 2000-------------\n",
      "\n",
      "solution error = 1.362252532999264e-09\n",
      "\n",
      "solution error = 3.1832350089189276e-09\n",
      "-------------Year of 2001-------------\n",
      "\n",
      "solution error = 9.74057456915034e-09\n",
      "\n",
      "solution error = 4.835655431634223e-09\n",
      "-------------Year of 2002-------------\n",
      "\n",
      "solution error = 4.964419986208668e-10\n",
      "\n",
      "solution error = 3.4363836221018573e-09\n"
     ]
    }
   ],
   "source": [
    "#+ Step 2 & 3:\n",
    "year_load = 1992\n",
    "def clust_reci(typ):\n",
    "    clust = []\n",
    "    reci = []\n",
    "\n",
    "    for i in range(30):\n",
    "        if typ == \"ubcm\":\n",
    "            edgelist_ens = np.loadtxt(f\"ubcm_sample/{i}.txt\")\n",
    "            net = nx.Graph()\n",
    "        else:\n",
    "            edgelist_ens = np.loadtxt(f\"dbcm_sample/{i}.txt\")\n",
    "            net = nx.DiGraph()\n",
    "\n",
    "        net.add_edges_from(edgelist_ens)\n",
    "        clust.append(nx.average_clustering(net))\n",
    "        \n",
    "        if typ == \"dbcm\":\n",
    "            reci.append(nx.reciprocity(net))\n",
    "    \n",
    "    return clust, reci\n",
    "        \n",
    "\n",
    "ave_clust_ubcm = []\n",
    "std_err_clust_ubcm = []\n",
    "ave_clust_dbcm = []\n",
    "ave_reci_dbcm = []\n",
    "std_err_clust_dbcm = []\n",
    "std_err_reci_dbcm = []\n",
    "\n",
    "for graph in graphs:\n",
    "    print(\"-------------Year of \" + str(year_load) + \"-------------\")\n",
    "    # then we convert it to numpy adjacency matrix\n",
    "    ubcm_adj_wdn = nx.to_numpy_array(graph.to_undirected())\n",
    "    dbcm_adj_wdn = nx.to_numpy_array(graph)\n",
    "\n",
    "    # and we initialize a NEMtropy UndirectedGraph object/directed\n",
    "    ubcm_graph = UndirectedGraph(ubcm_adj_wdn)\n",
    "    dbcm_graph = DirectedGraph(dbcm_adj_wdn)\n",
    "\n",
    "    # then we need to solve the maximum likelihood problem for the model of our choice\n",
    "    # model choices for UndirectedGraph are \"cm_exp\", \"ecm_exp\" \n",
    "    # and \"crema\" which is a faster implementation of \"ecm_exp\"\n",
    "    # don't worry about warnings, it's normal\n",
    "\n",
    "    ubcm_graph.solve_tool(model=\"cm_exp\")\n",
    "    dbcm_graph.solve_tool(model=\"dcm_exp\")\n",
    "\n",
    "    #sample 30 networks from the obtained distributions and \n",
    "\n",
    "    ubcm_graph.ensemble_sampler(30, cpu_n=1, output_dir=\"ubcm_sample/\")\n",
    "    dbcm_graph.ensemble_sampler(30, cpu_n=1, output_dir=\"dbcm_sample/\")\n",
    "\n",
    "    # measure clustering and reciprocity.\n",
    "    ubcm_clust = []\n",
    "    placeholder = []\n",
    "    dbcm_clust = []\n",
    "    dbcm_reci = []\n",
    "\n",
    "    ubcm_clust, placeholder = clust_reci(\"ubcm\")\n",
    "    dbcm_clust, dbcm_reci = clust_reci(\"dbcm\")\n",
    "    \n",
    "    # Calculate average and standard error on each measure\n",
    "    ave_clust_ubcm.append(np.average(ubcm_clust))\n",
    "    std_err_clust_ubcm.append(sem(ubcm_clust))\n",
    "\n",
    "    ave_clust_dbcm.append(np.average(dbcm_clust))\n",
    "    std_err_clust_dbcm.append(sem(dbcm_clust))\n",
    "    ave_reci_dbcm.append(np.average(dbcm_reci))\n",
    "    std_err_reci_dbcm.append(sem(dbcm_reci))\n",
    "\n",
    "    year_load = year_load + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A06.2 - Weighted ERGMs\n",
    "\n",
    "Task: Repeat the analysis of point 1 with weighted networks\n",
    "\n",
    "+ measure strength assortativity coefficient on the data\n",
    "\n",
    "+ fit the Undirected Enhanced CM and Directed Enhanced CM using the CReMa method\n",
    "\n",
    "+ sample 30 networks from the obtained distributions and measure strength assortativity. Calculate average and std dev\n",
    "\n",
    "+ plot strength assortativity as a function of time, comparing the real value with the average and error bars from samples\n",
    "\n",
    "+ DECM: plot all pairs of assortativity (in-in, in-out, out-out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
